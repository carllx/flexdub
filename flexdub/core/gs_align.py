"""
gs.md ä¸ SRT å¯¹é½æ¨¡å—

å®ç° gs.mdï¼ˆäººå·¥æ ¡å¯¹ç¨¿ï¼‰ä¸åŸå§‹ SRTï¼ˆç²¾ç¡®æ—¶é—´è½´ï¼‰çš„è¯­ä¹‰å¯¹é½ã€‚

æ ¸å¿ƒæ€è·¯ï¼š
- gs.md æä¾›é«˜è´¨é‡ç¿»è¯‘æ–‡æœ¬å’Œç²—ç•¥æ—¶é—´é”šç‚¹
- åŸå§‹ SRT æä¾›ç²¾ç¡®æ—¶é—´è½´
- å¯¹é½ç®—æ³•å°†ä¸¤è€…èåˆï¼Œç”Ÿæˆ TTS ç”¨çš„ audio.srt

è®¾è®¡å†³ç­–ï¼š
- ä½¿ç”¨è¯­ä¹‰è§£æè¯†åˆ« gs.md æ–‡æ¡£ç»“æ„
- åªæå–"å®Œæ•´é€å­—ç¨¿"éƒ¨åˆ†ï¼Œæ’é™¤å›¾åƒè¯´æ˜ã€æœ¯è¯­è¡¨ã€å­¦ä¹ ç¬”è®°
- æ”¯æŒå¤šè¯´è¯äººæ ‡ç­¾æå–å’Œä¼ æ’­
"""

import re
from dataclasses import dataclass, field
from typing import List, Optional, Tuple, Dict
from enum import Enum

from flexdub.core.subtitle import SRTItem
from flexdub.core.rebalance import Segment, rebalance_intervals


class SectionType(Enum):
    """gs.md æ–‡æ¡£éƒ¨åˆ†ç±»å‹"""
    TRANSCRIPT = "transcript"      # å®Œæ•´é€å­—ç¨¿ï¼ˆä¸»è¦å†…å®¹ï¼‰
    IMAGE_DESC = "image_desc"      # å›¾åƒè¡¥å……è¯´æ˜ï¼ˆæ’é™¤ï¼‰
    GLOSSARY = "glossary"          # é‡è¦æœ¯è¯­ï¼ˆæ’é™¤ï¼‰
    LEARNING = "learning"          # å­¦ä¹ æ”¶è·ï¼ˆæ’é™¤ï¼‰
    INFO = "info"                  # åŸºæœ¬ä¿¡æ¯ï¼ˆæ’é™¤ï¼‰
    UNKNOWN = "unknown"            # æœªçŸ¥éƒ¨åˆ†


@dataclass
class GSSegment:
    """gs.md ä¸­çš„ä¸€ä¸ªæ®µè½ï¼ˆå¢å¼ºç‰ˆï¼‰"""
    start_ms: int           # ä» ### [MM:SS] è§£æçš„æ—¶é—´é”šç‚¹
    speaker: str            # è¯´è¯äººåç§°
    text: str               # ç¿»è¯‘æ–‡æœ¬ï¼ˆå¯èƒ½æ˜¯å¤šä¸ªè‡ªç„¶æ®µï¼‰
    section_type: SectionType = SectionType.TRANSCRIPT  # éƒ¨åˆ†ç±»å‹


# ä¿ç•™æ—§çš„ GsParagraph ä½œä¸ºåˆ«åï¼Œä¿æŒå‘åå…¼å®¹
@dataclass
class GsParagraph:
    """gs.md ä¸­çš„ä¸€ä¸ªæ®µè½ï¼ˆå‘åå…¼å®¹ï¼‰"""
    anchor_ms: int      # ä» ### [MM:SS] è§£æçš„æ—¶é—´é”šç‚¹
    speaker: str        # è¯´è¯äººåç§°
    text: str           # ç¿»è¯‘æ–‡æœ¬ï¼ˆå¯èƒ½æ˜¯å¤šä¸ªè‡ªç„¶æ®µï¼‰
    

def parse_timestamp(ts_str: str) -> int:
    """
    è§£ææ—¶é—´æˆ³å­—ç¬¦ä¸²ä¸ºæ¯«ç§’
    æ”¯æŒæ ¼å¼: MM:SS æˆ– HH:MM:SS
    """
    parts = ts_str.strip().split(':')
    if len(parts) == 2:
        minutes, seconds = int(parts[0]), int(parts[1])
        return (minutes * 60 + seconds) * 1000
    elif len(parts) == 3:
        hours, minutes, seconds = int(parts[0]), int(parts[1]), int(parts[2])
        return (hours * 3600 + minutes * 60 + seconds) * 1000
    return 0


def identify_section_type(header: str) -> SectionType:
    """
    è¯­ä¹‰è¯†åˆ«æ–‡æ¡£éƒ¨åˆ†ç±»å‹
    
    Args:
        header: éƒ¨åˆ†æ ‡é¢˜ï¼ˆå¦‚ "## å®Œæ•´é€å­—ç¨¿"ï¼‰
        
    Returns:
        SectionType æšä¸¾å€¼
    """
    header_lower = header.lower().strip()
    
    # é€å­—ç¨¿éƒ¨åˆ†ï¼ˆä¸»è¦å†…å®¹ï¼‰
    transcript_markers = [
        'å®Œæ•´é€å­—ç¨¿', 'é€å­—ç¨¿', 'transcript', 'full transcript',
        'ç»§ç»­', 'q&a', 'qaéƒ¨åˆ†', 'é—®ç­”'
    ]
    for marker in transcript_markers:
        if marker in header_lower:
            return SectionType.TRANSCRIPT
    
    # å›¾åƒè¯´æ˜éƒ¨åˆ†ï¼ˆæ’é™¤ï¼‰
    image_markers = ['å›¾åƒ', 'ç”»é¢', 'image', 'è¡¥å……è¯´æ˜', 'ğŸ”']
    for marker in image_markers:
        if marker in header_lower:
            return SectionType.IMAGE_DESC
    
    # æœ¯è¯­è¡¨éƒ¨åˆ†ï¼ˆæ’é™¤ï¼‰
    glossary_markers = ['æœ¯è¯­', 'äººç‰©', 'glossary', 'terms', 'ğŸ“š']
    for marker in glossary_markers:
        if marker in header_lower:
            return SectionType.GLOSSARY
    
    # å­¦ä¹ æ”¶è·éƒ¨åˆ†ï¼ˆæ’é™¤ï¼‰
    learning_markers = ['å­¦ä¹ ', 'æ”¶è·', 'learning', 'æ€è€ƒ', 'ğŸ’¡']
    for marker in learning_markers:
        if marker in header_lower:
            return SectionType.LEARNING
    
    # åŸºæœ¬ä¿¡æ¯éƒ¨åˆ†ï¼ˆæ’é™¤ï¼‰
    info_markers = ['åŸºæœ¬ä¿¡æ¯', 'info', 'è§†é¢‘æ—¶é•¿', 'è®²è€…']
    for marker in info_markers:
        if marker in header_lower:
            return SectionType.INFO
    
    return SectionType.UNKNOWN


def find_transcript_sections(content: str) -> List[Tuple[int, int, SectionType]]:
    """
    æ‰¾åˆ°æ‰€æœ‰é€å­—ç¨¿éƒ¨åˆ†çš„ä½ç½®èŒƒå›´
    
    Args:
        content: gs.md æ–‡ä»¶å†…å®¹
        
    Returns:
        List of (start_pos, end_pos, section_type) tuples
    """
    # åŒ¹é…äºŒçº§æ ‡é¢˜ ## xxx
    section_pattern = re.compile(r'^##\s+(.+)$', re.MULTILINE)
    
    sections = []
    matches = list(section_pattern.finditer(content))
    
    for i, match in enumerate(matches):
        header = match.group(1)
        section_type = identify_section_type(header)
        start_pos = match.end()
        
        # ç¡®å®šéƒ¨åˆ†ç»“æŸä½ç½®ï¼ˆä¸‹ä¸€ä¸ªäºŒçº§æ ‡é¢˜æˆ–æ–‡ä»¶æœ«å°¾ï¼‰
        if i + 1 < len(matches):
            end_pos = matches[i + 1].start()
        else:
            end_pos = len(content)
        
        sections.append((start_pos, end_pos, section_type))
    
    return sections


def clean_text_for_tts(text: str, remove_english_in_parens: bool = True) -> str:
    """
    æ¸…ç†æ–‡æœ¬ä»¥é€‚åˆ TTS åˆæˆ
    
    Args:
        text: åŸå§‹æ–‡æœ¬
        remove_english_in_parens: æ˜¯å¦ç§»é™¤æ‹¬å·ä¸­çš„è‹±æ–‡åŸæ–‡
        
    Returns:
        æ¸…ç†åçš„æ–‡æœ¬
    """
    # ç§»é™¤ Markdown ç²—ä½“
    text = re.sub(r'\*\*([^*]+)\*\*', r'\1', text)
    
    # ç§»é™¤ Markdown æ–œä½“
    text = re.sub(r'\*([^*]+)\*', r'\1', text)
    
    # ç§»é™¤æ‹¬å·ä¸­çš„è‹±æ–‡åŸæ–‡ï¼ˆå¦‚ "ä¿®è¾å­¦ï¼ˆRhetoricï¼‰" â†’ "ä¿®è¾å­¦"ï¼‰
    # ä½†ä¿ç•™äººåç¿»è¯‘ï¼ˆå¦‚ "Noahï¼ˆè¯ºäºšï¼‰" ä¿ç•™ä¸º "è¯ºäºš"ï¼‰
    if remove_english_in_parens:
        # åŒ¹é…ä¸­æ–‡è¯åè·Ÿæ‹¬å·ä¸­çš„è‹±æ–‡
        text = re.sub(r'ï¼ˆ[A-Za-z][A-Za-z\s\-\'\.]+ï¼‰', '', text)
        text = re.sub(r'\([A-Za-z][A-Za-z\s\-\'\.]+\)', '', text)
        
        # å¯¹äºäººåï¼Œä¿ç•™ä¸­æ–‡ç¿»è¯‘ï¼šNoahï¼ˆè¯ºäºšï¼‰â†’ è¯ºäºš
        # åŒ¹é…è‹±æ–‡ååè·Ÿæ‹¬å·ä¸­çš„ä¸­æ–‡
        text = re.sub(r'([A-Z][a-z]+(?:\s+[A-Z][a-z]+)*)\s*ï¼ˆ([^ï¼‰]+)ï¼‰', r'\2', text)
        text = re.sub(r'([A-Z][a-z]+(?:\s+[A-Z][a-z]+)*)\s*\(([^)]+)\)', r'\2', text)
    
    # ç§»é™¤å›¾åƒæè¿°è¡Œï¼ˆå¦‚ "**[05:07]** ç”»é¢å†…å®¹ï¼š..."ï¼‰
    text = re.sub(r'\*\*\[\d{1,2}:\d{2}\]\*\*\s*ç”»é¢å†…å®¹[ï¼š:].+', '', text)
    
    # ç§»é™¤åˆ—è¡¨æ ‡è®°
    text = re.sub(r'^[-*]\s+', '', text, flags=re.MULTILINE)
    
    # ç§»é™¤å¤šä½™ç©ºç™½
    text = re.sub(r'\s+', ' ', text).strip()
    
    return text


def parse_gs_md(content: str) -> List[GsParagraph]:
    """
    è¯­ä¹‰è§£æ gs.md æ–‡ä»¶å†…å®¹
    
    åªæå–"å®Œæ•´é€å­—ç¨¿"éƒ¨åˆ†çš„å†…å®¹ï¼Œæ’é™¤ï¼š
    - å›¾åƒè¡¥å……è¯´æ˜
    - é‡è¦æœ¯è¯­å’Œäººç‰©
    - å­¦ä¹ æ”¶è·
    - åŸºæœ¬ä¿¡æ¯
    
    æ ¼å¼ç¤ºä¾‹:
    ### [00:00] Ian Bogost
    å¥½çš„ã€‚Noahï¼ˆè¯ºäºšï¼‰è®©æˆ‘æ¥è°ˆè°ˆ...
    
    ### [01:18] Ian Bogost
    ä½†å¦‚æœæˆ‘ä»¬å›é¡¾å†å²...
    
    Args:
        content: gs.md æ–‡ä»¶çš„å®Œæ•´å†…å®¹
        
    Returns:
        GsParagraph åˆ—è¡¨ï¼ŒåªåŒ…å«é€å­—ç¨¿éƒ¨åˆ†çš„æ®µè½
    """
    paragraphs: List[GsParagraph] = []
    
    # Step 1: æ‰¾åˆ°æ‰€æœ‰é€å­—ç¨¿éƒ¨åˆ†
    sections = find_transcript_sections(content)
    transcript_sections = [
        (start, end) for start, end, stype in sections 
        if stype == SectionType.TRANSCRIPT
    ]
    
    if not transcript_sections:
        # å¦‚æœæ²¡æœ‰æ‰¾åˆ°æ˜ç¡®çš„é€å­—ç¨¿éƒ¨åˆ†ï¼Œä½¿ç”¨æ—§çš„é€»è¾‘ä½œä¸ºå›é€€
        return _parse_gs_md_legacy(content)
    
    # Step 2: åˆå¹¶æ‰€æœ‰é€å­—ç¨¿éƒ¨åˆ†çš„å†…å®¹
    transcript_content = ""
    for start, end in transcript_sections:
        transcript_content += content[start:end] + "\n"
    
    # Step 3: åœ¨é€å­—ç¨¿å†…å®¹ä¸­æå–æ—¶é—´é”šç‚¹å’Œæ®µè½
    # åŒ¹é… ### [MM:SS] Speaker æˆ– ### [HH:MM:SS] Speaker
    header_pattern = re.compile(r'^###\s*\[(\d{1,2}:\d{2}(?::\d{2})?)\]\s*(.+)$', re.MULTILINE)
    
    headers = list(header_pattern.finditer(transcript_content))
    
    for i, match in enumerate(headers):
        timestamp_str = match.group(1)
        speaker = match.group(2).strip()
        anchor_ms = parse_timestamp(timestamp_str)
        
        # æå–è¯¥æ®µè½çš„æ–‡æœ¬ï¼ˆä»å½“å‰æ ‡é¢˜åˆ°ä¸‹ä¸€ä¸ªæ ‡é¢˜ä¹‹é—´ï¼‰
        start_pos = match.end()
        end_pos = headers[i + 1].start() if i + 1 < len(headers) else len(transcript_content)
        
        text = transcript_content[start_pos:end_pos].strip()
        
        # æ¸…ç†æ–‡æœ¬
        lines = [line.strip() for line in text.split('\n') if line.strip()]
        # è¿‡æ»¤æ‰ä»¥ ## æˆ– ### å¼€å¤´çš„è¡Œï¼ˆå¯èƒ½æ˜¯å…¶ä»–æ ‡é¢˜ï¼‰
        lines = [line for line in lines if not line.startswith('#')]
        # è¿‡æ»¤æ‰å›¾åƒè¯´æ˜ç­‰å…ƒä¿¡æ¯
        lines = [line for line in lines if not line.startswith('- **') and not line.startswith('**[')]
        
        # åˆå¹¶å¹¶æ¸…ç†æ–‡æœ¬
        raw_text = ' '.join(lines)
        cleaned_text = clean_text_for_tts(raw_text)
        
        if cleaned_text:
            paragraphs.append(GsParagraph(
                anchor_ms=anchor_ms,
                speaker=speaker,
                text=cleaned_text
            ))
    
    return paragraphs


def _parse_gs_md_legacy(content: str) -> List[GsParagraph]:
    """
    æ—§ç‰ˆ gs.md è§£æé€»è¾‘ï¼ˆä½œä¸ºå›é€€ï¼‰
    
    å½“æ— æ³•è¯†åˆ«æ–‡æ¡£ç»“æ„æ—¶ä½¿ç”¨
    """
    paragraphs: List[GsParagraph] = []
    
    # åŒ¹é… ### [MM:SS] Speaker æˆ– ### [HH:MM:SS] Speaker
    header_pattern = re.compile(r'^###\s*\[(\d{1,2}:\d{2}(?::\d{2})?)\]\s*(.+)$', re.MULTILINE)
    
    # æ£€æµ‹å†…å®¹ç»“æŸæ ‡è®°ï¼ˆå­¦ä¹ æ”¶è·ã€å›¾åƒè¯´æ˜ç­‰éé€å­—ç¨¿éƒ¨åˆ†ï¼‰
    end_markers = [
        '## ğŸ“š', '## ğŸ’¡', '## ğŸ”',  # Emoji æ ‡é¢˜
        '## é‡è¦æœ¯è¯­', '## æˆ‘çš„å­¦ä¹ ', '## å›¾åƒè¡¥å……',  # ä¸­æ–‡æ ‡é¢˜
        '## Important', '## My Learning', '## Image',  # è‹±æ–‡æ ‡é¢˜
    ]
    
    # æ‰¾åˆ°å†…å®¹ç»“æŸä½ç½®
    content_end = len(content)
    for marker in end_markers:
        pos = content.find(marker)
        if pos > 0 and pos < content_end:
            content_end = pos
    
    # åªå¤„ç†é€å­—ç¨¿éƒ¨åˆ†
    transcript_content = content[:content_end]
    
    # æ‰¾åˆ°æ‰€æœ‰æ ‡é¢˜ä½ç½®
    headers = list(header_pattern.finditer(transcript_content))
    
    for i, match in enumerate(headers):
        timestamp_str = match.group(1)
        speaker = match.group(2).strip()
        anchor_ms = parse_timestamp(timestamp_str)
        
        # æå–è¯¥æ®µè½çš„æ–‡æœ¬ï¼ˆä»å½“å‰æ ‡é¢˜åˆ°ä¸‹ä¸€ä¸ªæ ‡é¢˜ä¹‹é—´ï¼‰
        start_pos = match.end()
        end_pos = headers[i + 1].start() if i + 1 < len(headers) else len(transcript_content)
        
        text = transcript_content[start_pos:end_pos].strip()
        
        # æ¸…ç†æ–‡æœ¬ï¼šç§»é™¤ç©ºè¡Œï¼Œåˆå¹¶ä¸ºå•æ®µ
        lines = [line.strip() for line in text.split('\n') if line.strip()]
        # è¿‡æ»¤æ‰ä»¥ ## æˆ– ### å¼€å¤´çš„è¡Œï¼ˆå¯èƒ½æ˜¯å…¶ä»–æ ‡é¢˜ï¼‰
        lines = [line for line in lines if not line.startswith('#')]
        # è¿‡æ»¤æ‰å›¾åƒè¯´æ˜ç­‰å…ƒä¿¡æ¯
        lines = [line for line in lines if not line.startswith('- **') and not line.startswith('**[')]
        
        cleaned_text = ' '.join(lines)
        
        if cleaned_text:
            paragraphs.append(GsParagraph(
                anchor_ms=anchor_ms,
                speaker=speaker,
                text=cleaned_text
            ))
    
    return paragraphs


def extract_speakers(content: str) -> List[str]:
    """
    ä» gs.md ä¸­æå–æ‰€æœ‰å”¯ä¸€çš„è¯´è¯äººåç§°
    
    Args:
        content: gs.md æ–‡ä»¶å†…å®¹
        
    Returns:
        å”¯ä¸€è¯´è¯äººåç§°åˆ—è¡¨
    """
    paragraphs = parse_gs_md(content)
    speakers = []
    seen = set()
    
    for p in paragraphs:
        if p.speaker not in seen:
            speakers.append(p.speaker)
            seen.add(p.speaker)
    
    return speakers


class SpeakerTracker:
    """
    è¯´è¯äººè·Ÿè¸ªå™¨
    
    è·Ÿè¸ªå½“å‰è¯´è¯äººå¹¶ç®¡ç†è¯´è¯äººåˆ°éŸ³è‰²çš„æ˜ å°„ã€‚
    """
    
    DEFAULT_VOICE = "DEFAULT"
    
    def __init__(self, voice_map_path: Optional[str] = None):
        """
        åˆå§‹åŒ–è¯´è¯äººè·Ÿè¸ªå™¨
        
        Args:
            voice_map_path: voice_map.json æ–‡ä»¶è·¯å¾„ï¼ˆå¯é€‰ï¼‰
        """
        self.voice_map: Dict[str, str] = {}
        self.current_speaker: str = self.DEFAULT_VOICE
        self._speaker_timestamps: List[Tuple[int, str]] = []  # (timestamp_ms, speaker)
        
        if voice_map_path:
            self.load_voice_map(voice_map_path)
    
    def load_voice_map(self, path: str) -> None:
        """
        ä» JSON æ–‡ä»¶åŠ è½½è¯´è¯äººåˆ°éŸ³è‰²çš„æ˜ å°„
        
        Args:
            path: voice_map.json æ–‡ä»¶è·¯å¾„
        """
        import json
        from pathlib import Path
        
        voice_map_file = Path(path)
        if voice_map_file.exists():
            try:
                with open(voice_map_file, 'r', encoding='utf-8') as f:
                    self.voice_map = json.load(f)
            except json.JSONDecodeError as e:
                import warnings
                warnings.warn(f"voice_map.json æ ¼å¼é”™è¯¯: {e}ï¼Œä½¿ç”¨é»˜è®¤æ˜ å°„")
                self.voice_map = {}
    
    def set_speaker_anchors(self, gs_paragraphs: List[GsParagraph]) -> None:
        """
        ä» gs.md æ®µè½è®¾ç½®è¯´è¯äººæ—¶é—´é”šç‚¹
        
        Args:
            gs_paragraphs: è§£æåçš„ gs.md æ®µè½åˆ—è¡¨
        """
        self._speaker_timestamps = [
            (p.anchor_ms, p.speaker) for p in gs_paragraphs
        ]
        # æŒ‰æ—¶é—´æ’åº
        self._speaker_timestamps.sort(key=lambda x: x[0])
        
        # è®¾ç½®åˆå§‹è¯´è¯äºº
        if self._speaker_timestamps:
            self.current_speaker = self._speaker_timestamps[0][1]
    
    def update_speaker(self, timestamp_ms: int) -> str:
        """
        æ ¹æ®æ—¶é—´æˆ³æ›´æ–°å¹¶è¿”å›å½“å‰è¯´è¯äºº
        
        Args:
            timestamp_ms: å½“å‰æ—¶é—´æˆ³ï¼ˆæ¯«ç§’ï¼‰
            
        Returns:
            å½“å‰è¯´è¯äººåç§°
        """
        if not self._speaker_timestamps:
            return self.current_speaker
        
        # æ‰¾åˆ°æœ€è¿‘çš„è¯´è¯äººé”šç‚¹ï¼ˆä¸è¶…è¿‡å½“å‰æ—¶é—´ï¼‰
        for ts, speaker in reversed(self._speaker_timestamps):
            if ts <= timestamp_ms:
                self.current_speaker = speaker
                break
        
        return self.current_speaker
    
    def get_voice(self, speaker: str) -> str:
        """
        è·å–è¯´è¯äººå¯¹åº”çš„ TTS éŸ³è‰²
        
        Args:
            speaker: è¯´è¯äººåç§°
            
        Returns:
            TTS éŸ³è‰²æ ‡è¯†ç¬¦ï¼Œå¦‚æœæœªæ‰¾åˆ°åˆ™è¿”å› DEFAULT å¯¹åº”çš„éŸ³è‰²
        """
        if speaker in self.voice_map:
            return self.voice_map[speaker]
        
        # å›é€€åˆ° DEFAULT
        if self.DEFAULT_VOICE in self.voice_map:
            return self.voice_map[self.DEFAULT_VOICE]
        
        return self.DEFAULT_VOICE
    
    def generate_voice_map(self, speakers: List[str]) -> Dict[str, str]:
        """
        ç”Ÿæˆ voice_map.json æ¨¡æ¿
        
        Args:
            speakers: è¯´è¯äººåç§°åˆ—è¡¨
            
        Returns:
            åŒ…å«æ‰€æœ‰è¯´è¯äººçš„éŸ³è‰²æ˜ å°„å­—å…¸ï¼ˆå€¼ä¸ºå ä½ç¬¦ï¼‰
        """
        voice_map = {self.DEFAULT_VOICE: "ç£æ€§ä¿Šå®‡"}  # é»˜è®¤éŸ³è‰²
        
        for speaker in speakers:
            if speaker not in voice_map:
                # ä½¿ç”¨å ä½ç¬¦ï¼Œç”¨æˆ·éœ€è¦æ‰‹åŠ¨å¡«å†™
                voice_map[speaker] = f"<è¯·ä¸º {speaker} é€‰æ‹©éŸ³è‰²>"
        
        return voice_map
    
    def save_voice_map(self, path: str, speakers: List[str]) -> None:
        """
        ä¿å­˜ voice_map.json æ–‡ä»¶
        
        Args:
            path: ä¿å­˜è·¯å¾„
            speakers: è¯´è¯äººåç§°åˆ—è¡¨
        """
        import json
        from pathlib import Path
        
        voice_map = self.generate_voice_map(speakers)
        
        with open(path, 'w', encoding='utf-8') as f:
            json.dump(voice_map, f, ensure_ascii=False, indent=2)
    
    def validate_speakers(self, speakers: List[str]) -> List[str]:
        """
        éªŒè¯æ‰€æœ‰è¯´è¯äººæ˜¯å¦éƒ½æœ‰å¯¹åº”çš„éŸ³è‰²æ˜ å°„
        
        Args:
            speakers: è¯´è¯äººåç§°åˆ—è¡¨
            
        Returns:
            ç¼ºå¤±æ˜ å°„çš„è¯´è¯äººåˆ—è¡¨
        """
        missing = []
        for speaker in speakers:
            if speaker not in self.voice_map and speaker != self.DEFAULT_VOICE:
                missing.append(speaker)
        return missing


class TextSplitter:
    """
    æ–‡æœ¬åˆ†å‰²å™¨
    
    å¤„ç†æ–‡æœ¬æ¸…ç†å’Œ TTS ä¼˜åŒ–åˆ†å‰²ã€‚
    """
    
    MAX_CHARS = 75  # Doubao TTS å­—ç¬¦é™åˆ¶
    
    # å£è¯­å¡«å……è¯
    FILLERS = ['å—¯', 'å•Š', 'å‘ƒ', 'é¢', 'å“¦', 'å™¢', 'å””', 'å‘¢', 'å§', 'å•¦']
    
    def __init__(self, max_chars: int = 75):
        """
        åˆå§‹åŒ–æ–‡æœ¬åˆ†å‰²å™¨
        
        Args:
            max_chars: å•æ®µæœ€å¤§å­—ç¬¦æ•°
        """
        self.max_chars = max_chars
    
    def clean_markdown(self, text: str) -> str:
        """
        ç§»é™¤ Markdown æ ¼å¼
        
        Args:
            text: åŸå§‹æ–‡æœ¬
            
        Returns:
            æ¸…ç†åçš„æ–‡æœ¬
        """
        # ç§»é™¤ç²—ä½“ **text**
        text = re.sub(r'\*\*([^*]+)\*\*', r'\1', text)
        
        # ç§»é™¤æ–œä½“ *text*
        text = re.sub(r'\*([^*]+)\*', r'\1', text)
        
        # ç§»é™¤æ ‡é¢˜ # ## ###
        text = re.sub(r'^#+\s+', '', text, flags=re.MULTILINE)
        
        # ç§»é™¤åˆ—è¡¨æ ‡è®° - * 
        text = re.sub(r'^[-*]\s+', '', text, flags=re.MULTILINE)
        
        # ç§»é™¤é“¾æ¥ [text](url)
        text = re.sub(r'\[([^\]]+)\]\([^)]+\)', r'\1', text)
        
        # ç§»é™¤ä»£ç å— `code`
        text = re.sub(r'`([^`]+)`', r'\1', text)
        
        return text.strip()
    
    def remove_image_descriptions(self, text: str) -> str:
        """
        ç§»é™¤å›¾åƒæè¿°
        
        æ ¼å¼: **[MM:SS]** ç”»é¢å†…å®¹ï¼š...
        
        Args:
            text: åŸå§‹æ–‡æœ¬
            
        Returns:
            æ¸…ç†åçš„æ–‡æœ¬
        """
        # ç§»é™¤å¸¦æ—¶é—´æˆ³çš„å›¾åƒæè¿°ï¼ˆåˆ°å¥å·æˆ–æ¢è¡Œä¸ºæ­¢ï¼‰
        text = re.sub(r'\*\*\[\d{1,2}:\d{2}\]\*\*\s*ç”»é¢å†…å®¹[ï¼š:][^ã€‚\n]*[ã€‚]?', '', text)
        
        # ç§»é™¤å…¶ä»–å›¾åƒæè¿°æ ¼å¼ï¼ˆåˆ°å¥å·æˆ–æ¢è¡Œä¸ºæ­¢ï¼‰
        text = re.sub(r'ç”»é¢å†…å®¹[ï¼š:][^ã€‚\n]*[ã€‚]?', '', text)
        text = re.sub(r'å±å¹•æ˜¾ç¤º[ï¼š:][^ã€‚\n]*[ã€‚]?', '', text)
        
        return text.strip()
    
    def remove_fillers(self, text: str) -> str:
        """
        ç§»é™¤å£è¯­å¡«å……è¯
        
        Args:
            text: åŸå§‹æ–‡æœ¬
            
        Returns:
            æ¸…ç†åçš„æ–‡æœ¬
        """
        for filler in self.FILLERS:
            # ç§»é™¤å¥é¦–çš„å¡«å……è¯
            text = re.sub(rf'^{filler}[ï¼Œ,ã€]?\s*', '', text)
            # ç§»é™¤å¥ä¸­ç‹¬ç«‹çš„å¡«å……è¯ï¼ˆå‰åæœ‰æ ‡ç‚¹ï¼‰
            text = re.sub(rf'[ï¼Œ,ã€]\s*{filler}\s*[ï¼Œ,ã€]', 'ï¼Œ', text)
        
        # æ¸…ç†å¤šä½™çš„æ ‡ç‚¹
        text = re.sub(r'[ï¼Œ,]{2,}', 'ï¼Œ', text)
        
        return text.strip()
    
    def clean_all(self, text: str) -> str:
        """
        æ‰§è¡Œæ‰€æœ‰æ¸…ç†æ“ä½œ
        
        Args:
            text: åŸå§‹æ–‡æœ¬
            
        Returns:
            å®Œå…¨æ¸…ç†åçš„æ–‡æœ¬
        """
        text = self.clean_markdown(text)
        text = self.remove_image_descriptions(text)
        text = self.remove_fillers(text)
        
        # ç§»é™¤å¤šä½™ç©ºç™½
        text = re.sub(r'\s+', ' ', text).strip()
        
        return text
    
    def split_for_tts(self, text: str, max_chars: Optional[int] = None) -> List[str]:
        """
        æŒ‰è‡ªç„¶è¾¹ç•Œåˆ†å‰²æ–‡æœ¬ä»¥é€‚åˆ TTS
        
        ä¼˜å…ˆåœ¨å¥å·å¤„åˆ†å‰²ï¼Œå…¶æ¬¡åœ¨é€—å·å¤„åˆ†å‰²ã€‚
        
        Args:
            text: è¦åˆ†å‰²çš„æ–‡æœ¬
            max_chars: æœ€å¤§å­—ç¬¦æ•°ï¼ˆé»˜è®¤ä½¿ç”¨å®ä¾‹è®¾ç½®ï¼‰
            
        Returns:
            åˆ†å‰²åçš„æ–‡æœ¬åˆ—è¡¨
        """
        if max_chars is None:
            max_chars = self.max_chars
        
        if len(text) <= max_chars:
            return [text]
        
        # å¥å­ç»ˆæ­¢ç¬¦
        sentence_ends = re.compile(r'([ã€‚ï¼ï¼Ÿ.!?])')
        # æ¬¡çº§åˆ†éš”ç¬¦
        clause_ends = re.compile(r'([ï¼Œ,ï¼›;ï¼š:])')
        
        result: List[str] = []
        
        # é¦–å…ˆå°è¯•æŒ‰å¥å­æ‹†åˆ†
        parts = sentence_ends.split(text)
        # é‡æ–°ç»„åˆï¼ˆä¿ç•™æ ‡ç‚¹ï¼‰
        sentences = []
        i = 0
        while i < len(parts):
            if i + 1 < len(parts) and sentence_ends.match(parts[i + 1]):
                sentences.append(parts[i] + parts[i + 1])
                i += 2
            else:
                if parts[i].strip():
                    sentences.append(parts[i])
                i += 1
        
        # åˆå¹¶çŸ­å¥ï¼Œæ‹†åˆ†é•¿å¥
        current = ""
        for sent in sentences:
            if not sent.strip():
                continue
            if len(current) + len(sent) <= max_chars:
                current += sent
            else:
                if current:
                    result.append(current.strip())
                # å¦‚æœå•ä¸ªå¥å­å°±è¶…é•¿ï¼Œéœ€è¦åœ¨é€—å·å¤„æ‹†åˆ†
                if len(sent) > max_chars:
                    sub_parts = clause_ends.split(sent)
                    sub_current = ""
                    j = 0
                    while j < len(sub_parts):
                        part = sub_parts[j]
                        punct = sub_parts[j + 1] if j + 1 < len(sub_parts) and clause_ends.match(sub_parts[j + 1]) else ""
                        if punct:
                            j += 2
                        else:
                            j += 1
                        
                        chunk = part + punct
                        if len(sub_current) + len(chunk) <= max_chars:
                            sub_current += chunk
                        else:
                            if sub_current:
                                result.append(sub_current.strip())
                            sub_current = chunk
                    if sub_current:
                        current = sub_current
                    else:
                        current = ""
                else:
                    current = sent
        
        if current.strip():
            result.append(current.strip())
        
        return result if result else [text]


def find_matching_srt_range(
    anchor_ms: int,
    next_anchor_ms: int,
    srt_items: List[SRTItem],
    fuzzy_window_ms: int = 2000
) -> Tuple[int, int]:
    """
    æ‰¾åˆ°ä¸ gs æ®µè½å¯¹åº”çš„ SRT æ¡ç›®èŒƒå›´
    
    Args:
        anchor_ms: å½“å‰æ®µè½çš„æ—¶é—´é”šç‚¹
        next_anchor_ms: ä¸‹ä¸€ä¸ªæ®µè½çš„æ—¶é—´é”šç‚¹ï¼ˆç”¨äºç¡®å®šèŒƒå›´ç»ˆç‚¹ï¼‰
        srt_items: SRT æ¡ç›®åˆ—è¡¨
        fuzzy_window_ms: æ¨¡ç³ŠåŒ¹é…çª—å£ï¼ˆæ¯«ç§’ï¼‰ï¼Œå¤„ç†äººå·¥æ ‡æ³¨çš„æ—¶é—´è¯¯å·®
        
    Returns:
        (start_idx, end_idx): SRT æ¡ç›®çš„èµ·æ­¢ç´¢å¼•ï¼ˆåŒ…å« end_idxï¼‰
    """
    if not srt_items:
        return (0, 0)
    
    # Phase 1: æ‰¾åˆ°èµ·å§‹ç‚¹ï¼ˆå…è®¸æ¨¡ç³ŠåŒ¹é…ï¼‰
    start_idx = 0
    min_distance = float('inf')
    
    for i, item in enumerate(srt_items):
        # è®¡ç®— SRT æ¡ç›®ä¸­ç‚¹ä¸é”šç‚¹çš„è·ç¦»
        item_mid = (item.start_ms + item.end_ms) // 2
        distance = abs(item_mid - anchor_ms)
        
        # åœ¨é”šç‚¹é™„è¿‘ï¼ˆÂ±fuzzy_windowï¼‰å¯»æ‰¾æœ€ä½³åŒ¹é…
        if item.start_ms >= anchor_ms - fuzzy_window_ms:
            if distance < min_distance:
                min_distance = distance
                start_idx = i
            # å¦‚æœå·²ç»è¶…è¿‡é”šç‚¹å¤ªè¿œï¼Œåœæ­¢æœç´¢
            if item.start_ms > anchor_ms + fuzzy_window_ms:
                break
    
    # Phase 2: æ‰¾åˆ°ç»ˆæ­¢ç‚¹
    end_idx = start_idx
    for i in range(start_idx, len(srt_items)):
        # å¦‚æœ SRT æ¡ç›®çš„èµ·å§‹æ—¶é—´å·²ç»è¶…è¿‡ä¸‹ä¸€ä¸ªé”šç‚¹ï¼Œåœæ­¢
        if srt_items[i].start_ms >= next_anchor_ms - fuzzy_window_ms:
            break
        end_idx = i
    
    return (start_idx, end_idx)


def split_text_by_sentences(text: str, max_chars: int = 75) -> List[str]:
    """
    æŒ‰å¥å­æ‹†åˆ†æ–‡æœ¬ï¼Œç¡®ä¿æ¯æ®µä¸è¶…è¿‡ max_chars
    
    ä¼˜å…ˆåœ¨å¥å·å¤„æ‹†åˆ†ï¼Œå…¶æ¬¡åœ¨é€—å·å¤„æ‹†åˆ†
    """
    if len(text) <= max_chars:
        return [text]
    
    # å¥å­ç»ˆæ­¢ç¬¦
    sentence_ends = re.compile(r'([ã€‚ï¼ï¼Ÿ.!?])')
    # æ¬¡çº§åˆ†éš”ç¬¦
    clause_ends = re.compile(r'([ï¼Œ,ï¼›;ï¼š:])')
    
    result: List[str] = []
    
    # é¦–å…ˆå°è¯•æŒ‰å¥å­æ‹†åˆ†
    parts = sentence_ends.split(text)
    # é‡æ–°ç»„åˆï¼ˆä¿ç•™æ ‡ç‚¹ï¼‰
    sentences = []
    i = 0
    while i < len(parts):
        if i + 1 < len(parts) and sentence_ends.match(parts[i + 1]):
            sentences.append(parts[i] + parts[i + 1])
            i += 2
        else:
            if parts[i].strip():
                sentences.append(parts[i])
            i += 1
    
    # åˆå¹¶çŸ­å¥ï¼Œæ‹†åˆ†é•¿å¥
    current = ""
    for sent in sentences:
        if not sent.strip():
            continue
        if len(current) + len(sent) <= max_chars:
            current += sent
        else:
            if current:
                result.append(current.strip())
            # å¦‚æœå•ä¸ªå¥å­å°±è¶…é•¿ï¼Œéœ€è¦åœ¨é€—å·å¤„æ‹†åˆ†
            if len(sent) > max_chars:
                sub_parts = clause_ends.split(sent)
                sub_current = ""
                j = 0
                while j < len(sub_parts):
                    part = sub_parts[j]
                    punct = sub_parts[j + 1] if j + 1 < len(sub_parts) and clause_ends.match(sub_parts[j + 1]) else ""
                    if punct:
                        j += 2
                    else:
                        j += 1
                    
                    chunk = part + punct
                    if len(sub_current) + len(chunk) <= max_chars:
                        sub_current += chunk
                    else:
                        if sub_current:
                            result.append(sub_current.strip())
                        sub_current = chunk
                if sub_current:
                    current = sub_current
                else:
                    current = ""
            else:
                current = sent
    
    if current.strip():
        result.append(current.strip())
    
    return result if result else [text]


def align_gs_to_srt(
    gs_paragraphs: List[GsParagraph],
    srt_items: List[SRTItem],
    max_chars: int = 75,
    max_duration_ms: int = 15000,
    target_cpm: int = 180,
    fuzzy_window_ms: int = 2000,
    include_speaker_tags: bool = True
) -> List[SRTItem]:
    """
    å°† gs.md çš„ç¿»è¯‘æ–‡æœ¬ä¸åŸå§‹ SRT çš„æ—¶é—´è½´å¯¹é½
    
    **æ ¸å¿ƒè®¾è®¡**ï¼šä¿æŒåŸå§‹ SRT æ¡ç›®æ•°é‡ä¸å˜ï¼Œå¯¹æ¯ä¸ªåŸå§‹æ¡ç›®ï¼š
    - å¦‚æœè¢« gs.md è¦†ç›–ï¼Œä½¿ç”¨ gs.md ç¿»è¯‘
    - å¦‚æœæœªè¢«è¦†ç›–ï¼ˆè¶…å‡ºæœ€åé”šç‚¹ï¼‰ï¼Œä½¿ç”¨åŸå§‹ SRT æ–‡æœ¬ä½œä¸ºå›é€€
    
    Args:
        gs_paragraphs: ä» gs.md è§£æçš„æ®µè½åˆ—è¡¨
        srt_items: åŸå§‹ SRT æ¡ç›®åˆ—è¡¨
        max_chars: å•æ¡å­—å¹•æœ€å¤§å­—ç¬¦æ•°ï¼ˆDoubao TTS é™åˆ¶ï¼‰
        max_duration_ms: å•æ¡å­—å¹•æœ€å¤§æ—¶é•¿
        target_cpm: ç›®æ ‡ CPMï¼ˆç”¨äº rebalanceï¼‰
        fuzzy_window_ms: é”šç‚¹æ¨¡ç³ŠåŒ¹é…çª—å£
        include_speaker_tags: æ˜¯å¦åŒ…å«è¯´è¯äººæ ‡ç­¾
        
    Returns:
        å¯¹é½åçš„ SRT æ¡ç›®åˆ—è¡¨ï¼ˆä¿æŒåŸå§‹æ¡ç›®æ•°é‡ï¼‰
    """
    if not srt_items:
        return srt_items
    
    if not gs_paragraphs:
        # æ²¡æœ‰ gs.md å†…å®¹ï¼Œç›´æ¥è¿”å›åŸå§‹ SRT
        return srt_items
    
    result: List[SRTItem] = []
    
    # åˆå§‹åŒ–è¯´è¯äººè·Ÿè¸ªå™¨
    speaker_tracker = SpeakerTracker()
    speaker_tracker.set_speaker_anchors(gs_paragraphs)
    
    # è·å– gs.md çš„æœ€åä¸€ä¸ªé”šç‚¹æ—¶é—´ï¼ˆç”¨äºåˆ¤æ–­å›é€€ï¼‰
    last_anchor_ms = gs_paragraphs[-1].anchor_ms if gs_paragraphs else 0
    
    # æ„å»º gs æ®µè½çš„æ—¶é—´èŒƒå›´æ˜ å°„
    gs_ranges: List[Tuple[int, int, GsParagraph]] = []
    for i, gs in enumerate(gs_paragraphs):
        start_ms = gs.anchor_ms
        # ä¸‹ä¸€ä¸ªé”šç‚¹ä½œä¸ºç»“æŸæ—¶é—´ï¼Œæœ€åä¸€ä¸ªæ®µè½å»¶ä¼¸åˆ°è§†é¢‘ç»“æŸ
        if i + 1 < len(gs_paragraphs):
            end_ms = gs_paragraphs[i + 1].anchor_ms
        else:
            # æœ€åä¸€ä¸ªæ®µè½ï¼šå»¶ä¼¸åˆ°è§†é¢‘ç»“æŸæˆ–ä¸€ä¸ªåˆç†çš„æ—¶é—´
            end_ms = srt_items[-1].end_ms + 10000
        gs_ranges.append((start_ms, end_ms, gs))
    
    # ä¸ºæ¯ä¸ªåŸå§‹ SRT æ¡ç›®æ‰¾åˆ°å¯¹åº”çš„ gs.md å†…å®¹
    for srt_item in srt_items:
        sub_start_ms = srt_item.start_ms
        
        # è·å–å½“å‰æ—¶é—´ç‚¹çš„è¯´è¯äºº
        current_speaker = speaker_tracker.update_speaker(sub_start_ms)
        
        # æŸ¥æ‰¾è¦†ç›–æ­¤æ—¶é—´ç‚¹çš„ gs æ®µè½
        covering_gs: Optional[GsParagraph] = None
        for gs_start, gs_end, gs in gs_ranges:
            if gs_start <= sub_start_ms < gs_end:
                covering_gs = gs
                break
        
        if covering_gs:
            # è¢« gs.md è¦†ç›–ï¼Œä½¿ç”¨ gs.md ç¿»è¯‘
            # æ³¨æ„ï¼šè¿™é‡Œæˆ‘ä»¬éœ€è¦å°† gs æ®µè½çš„æ–‡æœ¬åˆ†é…ç»™å¤šä¸ª SRT æ¡ç›®
            # ç®€åŒ–å¤„ç†ï¼šä½¿ç”¨ gs æ®µè½çš„æ–‡æœ¬ï¼ˆåç»­ä¼šé€šè¿‡ distribute_text ä¼˜åŒ–ï¼‰
            text = covering_gs.text
            
            # å¦‚æœæ–‡æœ¬å¤ªé•¿ï¼Œéœ€è¦åˆ†å‰²
            if len(text) > max_chars:
                # ä½¿ç”¨ TextSplitter åˆ†å‰²
                splitter = TextSplitter(max_chars=max_chars)
                parts = splitter.split_for_tts(text)
                # å–ç¬¬ä¸€éƒ¨åˆ†ï¼ˆç®€åŒ–å¤„ç†ï¼Œå®é™…åº”è¯¥æŒ‰æ¯”ä¾‹åˆ†é…ï¼‰
                text = parts[0] if parts else text[:max_chars]
        else:
            # æœªè¢«è¦†ç›–ï¼ˆè¶…å‡º gs.md èŒƒå›´ï¼‰ï¼Œä½¿ç”¨åŸå§‹ SRT æ–‡æœ¬ä½œä¸ºå›é€€
            text = srt_item.text
        
        # æ·»åŠ è¯´è¯äººæ ‡ç­¾
        if include_speaker_tags:
            text = f"[Speaker: {current_speaker}] {text}"
        
        result.append(SRTItem(
            start_ms=srt_item.start_ms,
            end_ms=srt_item.end_ms,
            text=text
        ))
    
    return result


def align_gs_to_srt_v2(
    gs_paragraphs: List[GsParagraph],
    srt_items: List[SRTItem],
    max_chars: int = 75,
    include_speaker_tags: bool = True
) -> List[SRTItem]:
    """
    ä½¿ç”¨ gs.md ä¸ºåŸå§‹ SRT æ·»åŠ è¯´è¯äººæ ‡ç­¾
    
    æ ¸å¿ƒé€»è¾‘ï¼š
    - gs.md ä½œä¸ºèƒŒæ™¯å‚è€ƒä¿¡æ¯ï¼Œæä¾›è¯´è¯äººåˆ‡æ¢çš„æ—¶é—´ç‚¹
    - ä¿ç•™åŸå§‹ SRT çš„ç¿»è¯‘æ–‡æœ¬ä¸å˜
    - æ ¹æ® gs.md çš„æ—¶é—´é”šç‚¹ï¼Œä¸ºæ¯ä¸ª SRT æ¡ç›®æ·»åŠ æ­£ç¡®çš„è¯´è¯äººæ ‡ç­¾
    
    Args:
        gs_paragraphs: ä» gs.md è§£æçš„æ®µè½åˆ—è¡¨ï¼ˆæä¾›è¯´è¯äººä¿¡æ¯ï¼‰
        srt_items: åŸå§‹ SRT æ¡ç›®åˆ—è¡¨ï¼ˆå·²ç¿»è¯‘çš„æ–‡æœ¬ï¼‰
        max_chars: å•æ¡å­—å¹•æœ€å¤§å­—ç¬¦æ•°
        include_speaker_tags: æ˜¯å¦åŒ…å«è¯´è¯äººæ ‡ç­¾
        
    Returns:
        æ·»åŠ è¯´è¯äººæ ‡ç­¾åçš„ SRT æ¡ç›®åˆ—è¡¨ï¼ˆæ¡ç›®æ•°é‡ä¸åŸå§‹ SRT ç›¸åŒï¼‰
    """
    if not srt_items:
        return []
    
    if not gs_paragraphs:
        return srt_items
    
    result: List[SRTItem] = []
    
    # åˆå§‹åŒ–è¯´è¯äººè·Ÿè¸ªå™¨
    speaker_tracker = SpeakerTracker()
    speaker_tracker.set_speaker_anchors(gs_paragraphs)
    
    # å¤„ç†æ¯ä¸ªåŸå§‹ SRT æ¡ç›®
    for srt_item in srt_items:
        # æ ¹æ®æ—¶é—´æˆ³è·å–å½“å‰è¯´è¯äºº
        current_speaker = speaker_tracker.update_speaker(srt_item.start_ms)
        
        # ä¿ç•™åŸå§‹ SRT æ–‡æœ¬
        text = srt_item.text
        
        # æ·»åŠ è¯´è¯äººæ ‡ç­¾
        if include_speaker_tags:
            text = f"[Speaker: {current_speaker}] {text}"
        
        result.append(SRTItem(
            start_ms=srt_item.start_ms,
            end_ms=srt_item.end_ms,
            text=text
        ))
    
    return result


def fix_overlaps_and_gaps(items: List[SRTItem], min_gap_ms: int = 50) -> List[SRTItem]:
    """
    ä¿®å¤æ—¶é—´è½´é‡å å’Œè¿‡å°é—´éš™
    
    Args:
        items: SRT æ¡ç›®åˆ—è¡¨
        min_gap_ms: æœ€å°é—´éš™ï¼ˆæ¯«ç§’ï¼‰
        
    Returns:
        ä¿®å¤åçš„ SRT æ¡ç›®åˆ—è¡¨
    """
    if len(items) < 2:
        return items
    
    result = [items[0]]
    
    for i in range(1, len(items)):
        prev = result[-1]
        curr = items[i]
        
        # æ£€æŸ¥é‡å 
        if curr.start_ms < prev.end_ms:
            # æœ‰é‡å ï¼Œè°ƒæ•´å‰ä¸€æ¡çš„ç»“æŸæ—¶é—´
            mid_point = (prev.end_ms + curr.start_ms) // 2
            result[-1] = SRTItem(prev.start_ms, mid_point, prev.text)
            curr = SRTItem(mid_point, curr.end_ms, curr.text)
        
        # æ£€æŸ¥é—´éš™æ˜¯å¦è¿‡å°ï¼ˆä½†ä¸ä¸ºé›¶ï¼‰
        gap = curr.start_ms - result[-1].end_ms
        if 0 < gap < min_gap_ms:
            # é—´éš™è¿‡å°ï¼Œæ‰©å±•å‰ä¸€æ¡æ¥å¡«å……
            result[-1] = SRTItem(result[-1].start_ms, curr.start_ms, result[-1].text)
        
        result.append(curr)
    
    return result


def extract_glossary_from_gs(content: str) -> dict:
    """
    ä» gs.md ä¸­æå–æœ¯è¯­è¡¨
    
    è¯†åˆ«æ ¼å¼: Englishï¼ˆä¸­æ–‡ç¿»è¯‘ï¼‰æˆ– English (ä¸­æ–‡ç¿»è¯‘)
    """
    glossary = {}
    
    # åŒ¹é… Englishï¼ˆä¸­æ–‡ï¼‰ æˆ– English (ä¸­æ–‡) æ ¼å¼
    pattern = re.compile(r'\b([A-Z][a-zA-Z\s]+?)ï¼ˆ([^ï¼‰]+)ï¼‰|\b([A-Z][a-zA-Z\s]+?)\s*\(([^)]+)\)')
    
    for match in pattern.finditer(content):
        if match.group(1) and match.group(2):
            en, zh = match.group(1).strip(), match.group(2).strip()
        else:
            en, zh = match.group(3).strip(), match.group(4).strip()
        
        # è¿‡æ»¤æ‰å¤ªçŸ­çš„åŒ¹é…
        if len(en) >= 2 and len(zh) >= 1:
            glossary[en] = zh
    
    return glossary


@dataclass
class CoverageStats:
    """è¦†ç›–ç‡ç»Ÿè®¡"""
    total_entries: int          # æ€» SRT æ¡ç›®æ•°
    covered_entries: int        # è¢« gs.md è¦†ç›–çš„æ¡ç›®æ•°
    fallback_entries: int       # ä½¿ç”¨å›é€€çš„æ¡ç›®æ•°
    coverage_percent: float     # è¦†ç›–ç‡ç™¾åˆ†æ¯”
    last_anchor_time: str       # æœ€åä¸€ä¸ªé”šç‚¹æ—¶é—´
    video_duration: str         # è§†é¢‘æ€»æ—¶é•¿
    speakers: List[str]         # è¯´è¯äººåˆ—è¡¨


def calculate_coverage(
    gs_paragraphs: List[GsParagraph],
    srt_items: List[SRTItem]
) -> CoverageStats:
    """
    è®¡ç®— gs.md å¯¹ SRT çš„è¦†ç›–ç‡
    
    Args:
        gs_paragraphs: gs.md æ®µè½åˆ—è¡¨
        srt_items: åŸå§‹ SRT æ¡ç›®åˆ—è¡¨
        
    Returns:
        CoverageStats è¦†ç›–ç‡ç»Ÿè®¡
    """
    if not srt_items:
        return CoverageStats(
            total_entries=0,
            covered_entries=0,
            fallback_entries=0,
            coverage_percent=0.0,
            last_anchor_time="00:00",
            video_duration="00:00",
            speakers=[]
        )
    
    total = len(srt_items)
    video_end_ms = srt_items[-1].end_ms
    
    if not gs_paragraphs:
        return CoverageStats(
            total_entries=total,
            covered_entries=0,
            fallback_entries=total,
            coverage_percent=0.0,
            last_anchor_time="00:00",
            video_duration=f"{video_end_ms//60000}:{(video_end_ms//1000)%60:02d}",
            speakers=[]
        )
    
    # æœ€åä¸€ä¸ªé”šç‚¹æ—¶é—´
    last_anchor_ms = gs_paragraphs[-1].anchor_ms
    
    # è®¡ç®—è¦†ç›–çš„æ¡ç›®æ•°ï¼ˆåœ¨æœ€åä¸€ä¸ªé”šç‚¹ä¹‹å‰çš„æ¡ç›®ï¼‰
    covered = sum(1 for item in srt_items if item.start_ms <= last_anchor_ms + 60000)  # å…è®¸ 1 åˆ†é’Ÿç¼“å†²
    fallback = total - covered
    
    # æå–è¯´è¯äºº
    speakers = list(set(p.speaker for p in gs_paragraphs))
    
    return CoverageStats(
        total_entries=total,
        covered_entries=covered,
        fallback_entries=fallback,
        coverage_percent=100.0 * covered / total if total > 0 else 0.0,
        last_anchor_time=f"{last_anchor_ms//60000}:{(last_anchor_ms//1000)%60:02d}",
        video_duration=f"{video_end_ms//60000}:{(video_end_ms//1000)%60:02d}",
        speakers=speakers
    )


def validate_speakers(
    gs_speakers: List[str],
    voice_map: Dict[str, str]
) -> List[str]:
    """
    éªŒè¯æ‰€æœ‰è¯´è¯äººæ˜¯å¦éƒ½æœ‰å¯¹åº”çš„éŸ³è‰²æ˜ å°„
    
    Args:
        gs_speakers: gs.md ä¸­çš„è¯´è¯äººåˆ—è¡¨
        voice_map: éŸ³è‰²æ˜ å°„å­—å…¸
        
    Returns:
        ç¼ºå¤±æ˜ å°„çš„è¯´è¯äººåˆ—è¡¨
    """
    missing = []
    for speaker in gs_speakers:
        if speaker not in voice_map and speaker != "DEFAULT":
            missing.append(speaker)
    return missing


def generate_audio_srt(
    aligned_subs: List[SRTItem],
    include_speaker_tags: bool = True
) -> str:
    """
    ç”Ÿæˆ audio.srt å†…å®¹
    
    Args:
        aligned_subs: å¯¹é½åçš„ SRT æ¡ç›®åˆ—è¡¨
        include_speaker_tags: æ˜¯å¦åŒ…å«è¯´è¯äººæ ‡ç­¾
        
    Returns:
        SRT æ ¼å¼çš„å­—ç¬¦ä¸²
    """
    import srt
    from datetime import timedelta
    
    srt_subs = []
    for i, item in enumerate(aligned_subs):
        text = item.text
        
        # å¦‚æœä¸éœ€è¦è¯´è¯äººæ ‡ç­¾ï¼Œç§»é™¤å®ƒ
        if not include_speaker_tags and '[Speaker:' in text:
            text = text.split('] ', 1)[1] if '] ' in text else text
        
        srt_subs.append(srt.Subtitle(
            index=i + 1,
            start=timedelta(milliseconds=item.start_ms),
            end=timedelta(milliseconds=item.end_ms),
            content=text
        ))
    
    return srt.compose(srt_subs)
